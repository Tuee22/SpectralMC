from __future__ import annotations

from types import ModuleType
from typing import Sequence, Tuple, overload
import builtins as _b

# ─────────────────────────────────────────────────────
# dtype sentinel  (public name: torch.dtype)
# ─────────────────────────────────────────────────────
class dtype: ...

float32: dtype
float64: dtype
int64: dtype
float16: dtype
bfloat16: dtype
complex64: dtype
complex128: dtype
float: dtype
double: dtype
long: dtype

# ─────────────────────────────────────────────────────
# torch.device sentinel
# ─────────────────────────────────────────────────────
class device:
    def __init__(self, type: str, index: int | None = ...) -> None: ...

# ─────────────────────────────────────────────────────
# Tensor (only members touched by your code/tests)
# ─────────────────────────────────────────────────────
class Tensor:
    # construction / autograd
    def __init__(
        self, *size: int, dtype: dtype | None = ..., requires_grad: bool = ...
    ) -> None: ...
    def backward(self, gradient: Tensor | None = ...) -> None: ...
    grad: Tensor | None

    # shape & properties
    @property
    def dtype(self) -> dtype: ...
    @property
    def shape(self) -> tuple[int, ...]: ...
    @property
    def ndim(self) -> int: ...
    def mean(self, dim: int | None = ..., **kw: object) -> Tensor: ...
    def var(
        self, dim: int | None = ..., *, unbiased: bool = ..., **kw: object
    ) -> Tensor: ...
    def max(self, dim: int | None = ..., keepdim: bool = ...) -> Tensor: ...
    def sum(
        self, dim: int | None = ..., keepdim: bool = ..., *, dtype: dtype | None = ...
    ) -> Tensor: ...
    def unsqueeze(self, dim: int) -> Tensor: ...
    def squeeze(self, dim: int | None = ...) -> Tensor: ...
    def transpose(self, dim0: int, dim1: int) -> Tensor: ...
    @property
    def T(self) -> Tensor: ...

    # element-wise helpers
    def abs(self) -> Tensor: ...
    def pow(self, exponent: _b.int | _b.float) -> Tensor: ...
    def square(self) -> Tensor: ...
    def all(self) -> Tensor: ...

    # arithmetic
    def __add__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    __radd__ = __add__
    def __sub__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    __rsub__ = __sub__
    def __mul__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    __rmul__ = __mul__
    def __truediv__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def __rtruediv__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def __matmul__(self, other: Tensor) -> Tensor: ...

    # comparisons / masks
    def __lt__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def __le__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def __gt__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def __ge__(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def __and__(self, other: Tensor | bool) -> Tensor: ...
    __rand__ = __and__
    def __getitem__(self, item: object) -> Tensor: ...

    # in-place
    def mul_(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def add_(self, other: Tensor | _b.float | _b.int) -> Tensor: ...
    def copy_(self, other: Tensor) -> Tensor: ...
    def zero_(self) -> Tensor: ...
    def fill_(self, value: _b.int | _b.float) -> Tensor: ...

    # misc
    def detach(self) -> Tensor: ...
    def cpu(self) -> Tensor: ...
    def clone(self) -> Tensor: ...
    def reshape(
        self, shape: tuple[int, ...] | Sequence[int] | int, *more: int
    ) -> Tensor: ...
    def tolist(self) -> list[_b.int | _b.float]: ...
    def item(self) -> _b.int | _b.float: ...

# ─────────────────────────────────────────────────────
# functional helpers
# ─────────────────────────────────────────────────────
def zeros(*size: int, dtype: dtype | None = ...) -> Tensor: ...
def ones(
    *size: int, dtype: dtype | None = ..., device: device | str | None = ...
) -> Tensor: ...
def full(
    size: Tuple[int, ...], fill_value: _b.int | _b.float, dtype: dtype | None = ...
) -> Tensor: ...
def full_like(
    a: Tensor,
    fill_value: _b.int | _b.float,
    *,
    dtype: dtype | None = ...,
    device: device | str | None = ...,
) -> Tensor: ...
def zeros_like(a: Tensor) -> Tensor: ...
def matmul(a: Tensor, b: Tensor) -> Tensor: ...
def sqrt(a: Tensor) -> Tensor: ...
def clamp(
    a: Tensor,
    *,
    min: _b.int | _b.float | None = ...,
    max: _b.int | _b.float | None = ...,
) -> Tensor: ...
def relu(a: Tensor) -> Tensor: ...
def stack(tensors: Sequence[Tensor], dim: int = ...) -> Tensor: ...
def square(a: Tensor) -> Tensor: ...
def all(a: Tensor) -> _b.bool: ...
def allclose(
    a: Tensor, b: Tensor, *, atol: _b.float = ..., rtol: _b.float = ...
) -> _b.bool: ...
def isfinite(a: Tensor) -> Tensor: ...

# random helpers
def manual_seed(seed: int) -> None: ...
def randn(
    *size: int,
    dtype: dtype | None = ...,
    device: device | str | None = ...,
    requires_grad: bool = ...,
) -> Tensor: ...

# tensor() overloads
@overload
def tensor(
    data: _b.int | _b.float,
    *,
    dtype: dtype | None = ...,
    device: device | str | None = ...,
    requires_grad: _b.bool = ...,
) -> Tensor: ...
@overload
def tensor(
    data: Sequence[_b.int | _b.float],
    *,
    dtype: dtype | None = ...,
    device: device | str | None = ...,
    requires_grad: _b.bool = ...,
) -> Tensor: ...
@overload
def tensor(
    data: Sequence[Sequence[_b.int | _b.float]],
    *,
    dtype: dtype | None = ...,
    device: device | str | None = ...,
    requires_grad: _b.bool = ...,
) -> Tensor: ...

# no_grad
class _NoGrad:
    def __enter__(self) -> None: ...
    def __exit__(
        self,
        exc_type: type[BaseException] | None,
        exc: BaseException | None,
        tb: object | None,
    ) -> None: ...

def no_grad() -> _NoGrad: ...

# ─────────────────────────────────────────────────────
# torch.nn placeholder with visible Module attribute
# ─────────────────────────────────────────────────────
class _NNStub(ModuleType):
    Module: type

nn: _NNStub
linalg: ModuleType
